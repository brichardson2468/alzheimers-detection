{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications import VGG16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and configuration\n",
    "DATA_DIR = Path(\"/Users/bradrichardson/alzheimers-detection/data\")\n",
    "MODEL_SAVE_PATH = Path(\"models/alzheimer_model.h5\")\n",
    "HISTORY_SAVE_PATH = Path(\"models/training_history.npy\")\n",
    "CLASSES = [\"non_demented\", \"very_mild_dementia\", \"mild_dementia\", \"moderate_dementia\"]\n",
    "IMAGE_SIZE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights\n",
    "class_weights = {\n",
    "    0: 0.32,  # non_demented\n",
    "    1: 1.57,  # very_mild_dementia\n",
    "    2: 4.32,  # mild_dementia\n",
    "    3: 44.25  # moderate_dementia\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_data(data_dir, classes, image_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(np.array(range(len(classes))).reshape(-1, 1))\n",
    "    \n",
    "    for i, cls in enumerate(classes):\n",
    "        class_dir = data_dir / cls\n",
    "        for img_path in class_dir.glob(\"*.jpg\"):\n",
    "            try:\n",
    "                img = Image.open(img_path).resize(image_size)\n",
    "                img_array = np.array(img)\n",
    "                if img_array.shape == (*image_size, 3):  # Ensure consistent image shape\n",
    "                    data.append(img_array)\n",
    "                    labels.append(encoder.transform([[i]]).toarray().flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data, result = load_data(DATA_DIR, CLASSES, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, validation, and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.15, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using a pre-trained VGG16\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and training history\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "np.save(HISTORY_SAVE_PATH, history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
